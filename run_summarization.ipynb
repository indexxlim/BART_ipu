{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "926116a2-ac08-459a-8f43-a50e0b893fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdcc0149-ee9a-40da-99c9-c251efb95545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import sys\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from packaging import version\n",
    "\n",
    "import datasets\n",
    "import nltk  # Here to have a nice missing dependency error message early on\n",
    "import numpy as np\n",
    "from datasets import load_dataset, load_metric\n",
    "import yaml\n",
    "from easydict import EasyDict\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from filelock import FileLock\n",
    "from optimum.graphcore import IPUSeq2SeqTrainer#, IPUConfig\n",
    "from model.ipu_configuration import IPUConfig\n",
    "\n",
    "from optimum.graphcore import IPUSeq2SeqTrainingArguments as Seq2SeqTrainingArguments\n",
    "from optimum.graphcore.modeling_utils import to_pipelined\n",
    "\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    AutoTokenizer,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    HfArgumentParser,\n",
    "    MBart50Tokenizer,\n",
    "    MBart50TokenizerFast,\n",
    "    MBartTokenizer,\n",
    "    MBartTokenizerFast,\n",
    "    set_seed,\n",
    ")\n",
    "from transformers.trainer_utils import get_last_checkpoint\n",
    "from transformers.utils import check_min_version as tf_check_min_version\n",
    "from transformers.utils import is_offline_mode\n",
    "from transformers.utils.versions import require_version\n",
    "\n",
    "\n",
    "\n",
    "from sum_dataloader import SummaryCollator, get_dataloader, get_train_sampler, ipu_dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98a9050-86d5-414a-88f0-600a5d22821e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8954410b-2ed9-4732-8066-f78a63293554",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3f2165a-31c1-43eb-b4af-23d71f1da6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "__version__ = \"0.2.4.dev\"\n",
    "\n",
    "def check_min_version(min_version):\n",
    "    if version.parse(__version__) < version.parse(min_version):\n",
    "        if \"dev\" in min_version:\n",
    "            error_message = \"This example requires a source install from HuggingFace Optimum-Graphcore\"\n",
    "        else:\n",
    "            error_message = f\"This example requires a minimum version of {min_version},\"\n",
    "        error_message += f\" but the version found is {__version__}.\\n\"\n",
    "        raise ImportError(error_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae8f1a6b-c860-4f06-95c2-12294b17567c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ecf8c-6a79-41c5-89ca-4f7485a77dd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9fcc829b-9352-42c4-b92c-87a087ef3be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Will error if the minimal version of Transformers is not installed. Remove at your own risks.\n",
    "#tf_check_min_version(\"4.19.0.dev0\")\n",
    "\n",
    "# Will error if the minimal version of Optimum Graphcore is not installed. Remove at your own risks.\n",
    "check_min_version(\"0.2.4.dev\")\n",
    "\n",
    "require_version(\"datasets>=1.8.0\", \"To fix: pip install -r examples/pytorch/summarization/requirements.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80d099a-1341-432e-a047-5c8ef41ac272",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fb866fe-5b62-4b7e-a081-bcc07fdecfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    nltk.data.find(\"tokenizers/punkt\")\n",
    "except (LookupError, OSError):\n",
    "    if is_offline_mode():\n",
    "        raise LookupError(\n",
    "            \"Offline mode: run this script without TRANSFORMERS_OFFLINE first to download nltk data files\"\n",
    "        )\n",
    "    with FileLock(\".lock\") as lock:\n",
    "        nltk.download(\"punkt\", quiet=True)\n",
    "\n",
    "# A list of all multilingual tokenizer which require lang attribute.\n",
    "MULTILINGUAL_TOKENIZERS = [MBartTokenizer, MBartTokenizerFast, MBart50Tokenizer, MBart50TokenizerFast]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7742d36c-52a8-4fb7-824c-7c964a30a393",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8712459e-df87-4d9c-b9d7-425ca0e840f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2eea6248-7af8-422a-a02e-0b95cfd319cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 07:03:26 - INFO - __main__ - Training/evaluation parameters  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)],\n",
    ")\n",
    "log_level = -1 # training_args.get_process_log_level()\n",
    "logger.setLevel(log_level)\n",
    "datasets.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.set_verbosity(log_level)\n",
    "transformers.utils.logging.enable_default_handler()\n",
    "transformers.utils.logging.enable_explicit_format()\n",
    "\n",
    "logger.info(f\"Training/evaluation parameters  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e4b78b-1a6d-4ecd-9ef0-595f7e049de9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73630f10-2dcd-4b62-a712-e83e1ff7e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "argus = {}\n",
    "with open('configuration/summrization.yaml') as f:\n",
    "    hparams = yaml.load_all(f, Loader=yaml.FullLoader)\n",
    "    for argu in hparams:\n",
    "        argus[list(argu.keys())[0]]=list(argu.values())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e58c9386-a817-447d-96b4-fb4426c9b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_args, data_args, training_args = argus['ModelArguments'], argus['DataTrainingArguments'], argus['IPUSeq2SeqTrainingArguments']\n",
    "model_args, data_args = EasyDict(model_args), EasyDict(data_args)\n",
    "training_args = Seq2SeqTrainingArguments(**training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613a1689-4ce3-4aaf-ad9d-38ec266f04c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "694cd942-fe6a-457f-a811-605b1ba08189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detecting last checkpoint.\n",
    "last_checkpoint = None\n",
    "if os.path.isdir(training_args.output_dir) and training_args.do_train and not training_args.overwrite_output_dir:\n",
    "    last_checkpoint = get_last_checkpoint(training_args.output_dir)\n",
    "    if last_checkpoint is None and len(os.listdir(training_args.output_dir)) > 0:\n",
    "        raise ValueError(\n",
    "            f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"\n",
    "            \"Use --overwrite_output_dir to overcome.\"\n",
    "        )\n",
    "    elif last_checkpoint is not None and training_args.resume_from_checkpoint is None:\n",
    "        logger.info(\n",
    "            f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"\n",
    "            \"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5114fadf-4698-4c26-a0d2-911453dad3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "93a4ac6f-448f-42f0-a30f-fcc44e9a18eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|configuration_utils.py:654] 2022-04-29 07:03:33,990 >> loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "[INFO|configuration_utils.py:690] 2022-04-29 07:03:33,992 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|tokenization_auto.py:344] 2022-04-29 07:03:36,610 >> Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "[INFO|configuration_utils.py:654] 2022-04-29 07:03:37,428 >> loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "[INFO|configuration_utils.py:690] 2022-04-29 07:03:37,429 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[DEBUG|tokenization_utils_base.py:1750] 2022-04-29 07:03:41,567 >> facebook/bart-base does not contain a file named https://huggingface.co/facebook/bart-base/resolve/main/added_tokens.json.\n",
      "[DEBUG|tokenization_utils_base.py:1750] 2022-04-29 07:03:42,375 >> facebook/bart-base does not contain a file named https://huggingface.co/facebook/bart-base/resolve/main/special_tokens_map.json.\n",
      "[DEBUG|tokenization_utils_base.py:1750] 2022-04-29 07:03:43,316 >> facebook/bart-base does not contain a file named https://huggingface.co/facebook/bart-base/resolve/main/tokenizer_config.json.\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-04-29 07:03:43,316 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/vocab.json from cache at /root/.cache/huggingface/transformers/43978bdeaa326572886b44fcfed82f932f76571095ce31973e51c3da8ccade7f.d67d6b367eb24ab43b08ad55e014cf254076934f71d832bbab9ad35644a375ab\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-04-29 07:03:43,316 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/merges.txt from cache at /root/.cache/huggingface/transformers/3c167ed8af56e6605eeb794b63a79d65d85e6708c9b04408d41946337030f5cd.5d12962c5ee615a4c803841266e9c3be9a691a924f72d395d3a6c6c81157788b\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-04-29 07:03:43,317 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/a878fcd69bba037c9b1b227f4213579ae43d0aaa9374e167bc6c5f41b1cfeb30.fc9576039592f026ad76a1c231b89aee8668488c671dfbe6616bab2ed298d730\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-04-29 07:03:43,317 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-04-29 07:03:43,317 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/special_tokens_map.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1778] 2022-04-29 07:03:43,317 >> loading file https://huggingface.co/facebook/bart-base/resolve/main/tokenizer_config.json from cache at None\n",
      "[INFO|configuration_utils.py:654] 2022-04-29 07:03:44,261 >> loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "[INFO|configuration_utils.py:690] 2022-04-29 07:03:44,262 >> Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.18.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:1772] 2022-04-29 07:03:45,127 >> loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "[INFO|modeling_utils.py:2057] 2022-04-29 07:03:46,475 >> All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "[INFO|modeling_utils.py:2066] 2022-04-29 07:03:46,477 >> All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# See more about loading any type of standard or custom dataset (from files, python dict, pandas DataFrame, etc) at\n",
    "# https://huggingface.co/docs/datasets/loading_datasets.html.\n",
    "\n",
    "# Load pretrained model and tokenizer\n",
    "#\n",
    "# Distributed training:\n",
    "# The .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab.\n",
    "config = AutoConfig.from_pretrained(\n",
    "    model_args.config_name if model_args.config_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "ipu_config = IPUConfig.from_pretrained(\n",
    "    training_args.ipu_config_name if training_args.ipu_config_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_args.tokenizer_name if model_args.tokenizer_name else model_args.model_name_or_path,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    use_fast=model_args.use_fast_tokenizer,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_args.model_name_or_path,\n",
    "    from_tf=bool(\".ckpt\" in model_args.model_name_or_path),\n",
    "    config=config,\n",
    "    cache_dir=model_args.cache_dir,\n",
    "    revision=model_args.model_revision,\n",
    "    use_auth_token=True if model_args.use_auth_token else None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b1becb-b453-4ce4-a199-6ab54e29ad53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50265, 768, padding_idx=1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d98a3b-2777-4ac9-a88b-dcf954396c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927c7cd9-8b1f-40d1-88c3-975a3dcfab6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19180bf2-b0db-4bf2-ae15-b9253fc07570",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.pipeline_bart import PipelinedBartForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68f2df76-3fa4-4153-86e1-8c15a9c4e63e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PipelinedBartForConditionalGeneration.from_transformers(model, ipu_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a03e47-203d-401e-a65f-fca0f6cf76f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6226308-014f-426a-a8c1-10ae46179552",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "036ee102-dcaa-4978-8ac0-1b47c57c8c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = to_pipelined(model, ipu_config, force=False)\n",
    "model.parallelize()\n",
    "if not training_args.fp32:\n",
    "    model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd4068c-56a9-47f4-a58f-2d88cf06ff0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119616f-d392-4673-9d59-1b3ea41a6e09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28db510-a17c-4eaa-9d9d-9b4d848ad9fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1527ca95-cd01-404a-8b16-896e236134a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82b201f8-287f-4cff-a9ed-84b69d209a54",
   "metadata": {},
   "source": [
    "# Data make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d95eabb-1198-4ef4-87a6-c20126652127",
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_name_mapping = {\n",
    "    \"amazon_reviews_multi\": (\"review_body\", \"review_title\"),\n",
    "    \"big_patent\": (\"description\", \"abstract\"),\n",
    "    \"cnn_dailymail\": (\"article\", \"highlights\"),\n",
    "    \"orange_sum\": (\"text\", \"summary\"),\n",
    "    \"pn_summary\": (\"article\", \"summary\"),\n",
    "    \"psc\": (\"extract_text\", \"summary_text\"),\n",
    "    \"samsum\": (\"dialogue\", \"summary\"),\n",
    "    \"thaisum\": (\"body\", \"summary\"),\n",
    "    \"xglue\": (\"news_body\", \"news_title\"),\n",
    "    \"xsum\": (\"document\", \"summary\"),\n",
    "    \"wiki_summary\": (\"article\", \"highlights\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c6ff91-5be3-4c8e-bc32-60b67a3a2fea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8ea8569-897a-451e-b685-3872036336b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cnn_dailymail'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_args.dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a87def9-f122-47b6-bc0e-d8b6ae5a5a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/29/2022 07:19:42 - DEBUG - datasets.load - Checking /root/.cache/huggingface/datasets/downloads/12660d351f66522858b33549dc51dcb9e2175c19106780ee8f29e3dc4af71195.ef876a56bbc40513db0e303f5b9afb0e07995a4dd89f5f5a9a339ffdb1da19a5.py for additional imports.\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140450581330800 on /root/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Lock 140450581330800 acquired on /root/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Attempting to release lock 140450581330800 on /root/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Lock 140450581330800 released on /root/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.load - Created importable dataset file at /root/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cnn_dailymail.py\n",
      "04/29/2022 07:19:42 - INFO - datasets.info - Loading Dataset Infos from /root/.cache/huggingface/modules/datasets_modules/datasets/cnn_dailymail/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140452222589864 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Lock 140452222589864 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - INFO - datasets.builder - Overwrite dataset info from restored data version.\n",
      "04/29/2022 07:19:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Attempting to release lock 140452222589864 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Lock 140452222589864 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Attempting to acquire lock 140452222589864 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Lock 140452222589864 acquired on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - WARNING - datasets.builder - Reusing dataset cnn_dailymail (/root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234)\n",
      "04/29/2022 07:19:42 - INFO - datasets.info - Loading Dataset info from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Attempting to release lock 140452222589864 on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.utils.filelock - Lock 140452222589864 released on /root/.cache/huggingface/datasets/_root_.cache_huggingface_datasets_cnn_dailymail_3.0.0_3.0.0_3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234.lock\n",
      "04/29/2022 07:19:42 - DEBUG - datasets.builder - Constructing Dataset for split train, validation, test, from /root/.cache/huggingface/datasets/cnn_dailymail/3.0.0/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a41e271c78a4d6d8474a0a67a5446ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Set seed before initializing model.\n",
    "set_seed(training_args.seed)\n",
    "\n",
    "# Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)\n",
    "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/\n",
    "# (the dataset will be downloaded automatically from the datasets Hub).\n",
    "#\n",
    "# For CSV/JSON files this script will use the first column for the full texts and the second column for the\n",
    "# summaries (unless you specify column names for this with the `text_column` and `summary_column` arguments).\n",
    "#\n",
    "# In distributed training, the load_dataset function guarantee that only one local process can concurrently\n",
    "# download the dataset.\n",
    "if data_args.dataset_name is not None:\n",
    "    # Downloading and loading a dataset from the hub.\n",
    "    raw_datasets = load_dataset(\n",
    "        data_args.dataset_name,\n",
    "        data_args.dataset_config_name,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n",
    "else:\n",
    "    data_files = {}\n",
    "    if data_args.train_file is not None:\n",
    "        data_files[\"train\"] = data_args.train_file\n",
    "        extension = data_args.train_file.split(\".\")[-1]\n",
    "    if data_args.validation_file is not None:\n",
    "        data_files[\"validation\"] = data_args.validation_file\n",
    "        extension = data_args.validation_file.split(\".\")[-1]\n",
    "    if data_args.test_file is not None:\n",
    "        data_files[\"test\"] = data_args.test_file\n",
    "        extension = data_args.test_file.split(\".\")[-1]\n",
    "    raw_datasets = load_dataset(\n",
    "        extension,\n",
    "        data_files=data_files,\n",
    "        cache_dir=model_args.cache_dir,\n",
    "        use_auth_token=True if model_args.use_auth_token else None,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b25104-6646-4d56-9902-00dab89bf8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce9994-0f5a-4543-a2b2-4b148f199e6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a9e8ef4-ac9e-4d46-819f-19d8d8f8acbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = data_args.source_prefix if data_args.source_prefix is not None else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1406cc14-0511-4d23-9498-80ac33e99422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing the datasets.\n",
    "# We need to tokenize inputs and targets.\n",
    "if training_args.do_train:\n",
    "    column_names = raw_datasets[\"train\"].column_names\n",
    "elif training_args.do_eval:\n",
    "    column_names = raw_datasets[\"validation\"].column_names\n",
    "elif training_args.do_predict:\n",
    "    column_names = raw_datasets[\"test\"].column_names\n",
    "else:\n",
    "    logger.info(\"There is nothing to do. Please pass `do_train`, `do_eval` and/or `do_predict`.\")\n",
    "    raise\n",
    "\n",
    "if isinstance(tokenizer, tuple(MULTILINGUAL_TOKENIZERS)):\n",
    "    assert (\n",
    "        data_args.lang is not None\n",
    "    ), f\"{tokenizer.__class__.__name__} is a multilingual tokenizer which requires --lang argument\"\n",
    "\n",
    "    tokenizer.src_lang = data_args.lang\n",
    "    tokenizer.tgt_lang = data_args.lang\n",
    "\n",
    "    # For multilingual translation models like mBART-50 and M2M100 we need to force the target language token\n",
    "    # as the first generated token. We ask the user to explicitly provide this as --forced_bos_token argument.\n",
    "    forced_bos_token_id = (\n",
    "        tokenizer.lang_code_to_id[data_args.forced_bos_token] if data_args.forced_bos_token is not None else None\n",
    "    )\n",
    "    model.config.forced_bos_token_id = forced_bos_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "570637de-3e3a-4533-8de4-256e2e884f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92d4b68-d7d0-41bf-84d7-601a487c408b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2319f6c-1399-418c-95bf-4a1234d0dbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Get the column names for input/target.\n",
    "# dataset_columns = summarization_name_mapping.get(data_args.dataset_name, None)\n",
    "# if data_args.text_column is None:\n",
    "#     text_column = dataset_columns[0] if dataset_columns is not None else column_names[0]\n",
    "# else:\n",
    "#     text_column = data_args.text_column\n",
    "#     if text_column not in column_names:\n",
    "#         raise ValueError(\n",
    "#             f\"--text_column' value '{data_args.text_column}' needs to be one of: {', '.join(column_names)}\"\n",
    "#         )\n",
    "# if data_args.summary_column is None:\n",
    "#     summary_column = dataset_columns[1] if dataset_columns is not None else column_names[1]\n",
    "# else:\n",
    "#     summary_column = data_args.summary_column\n",
    "#     if summary_column not in column_names:\n",
    "#         raise ValueError(\n",
    "#             f\"--summary_column' value '{data_args.summary_column}' needs to be one of: {', '.join(column_names)}\"\n",
    "#         )\n",
    "\n",
    "# # Temporarily set max_target_length for training.\n",
    "# max_target_length = data_args.max_target_length\n",
    "# padding = \"max_length\" if data_args.pad_to_max_length else False\n",
    "\n",
    "# if training_args.label_smoothing_factor > 0 and not hasattr(model, \"prepare_decoder_input_ids_from_labels\"):\n",
    "#     logger.warning(\n",
    "#         \"label_smoothing is enabled but the `prepare_decoder_input_ids_from_labels` method is not defined for\"\n",
    "#         f\"`{model.__class__.__name__}`. This will lead to loss being calculated twice and will take up more memory\"\n",
    "#     )\n",
    "\n",
    "# def preprocess_function(examples):\n",
    "#     # remove pairs where at least one record is None\n",
    "\n",
    "#     inputs, targets = [], []\n",
    "#     for i in range(len(examples[text_column])):\n",
    "#         if examples[text_column][i] is not None and examples[summary_column][i] is not None:\n",
    "#             inputs.append(examples[text_column][i])\n",
    "#             targets.append(examples[summary_column][i])\n",
    "\n",
    "#     inputs = [prefix + inp for inp in inputs]\n",
    "#     model_inputs = tokenizer(inputs, max_length=data_args.max_source_length, padding=padding, truncation=True)\n",
    "\n",
    "#     # Setup the tokenizer for targets\n",
    "#     with tokenizer.as_target_tokenizer():\n",
    "#         labels = tokenizer(targets, max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "#     # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "#     # padding in the loss.\n",
    "#     if padding == \"max_length\" and data_args.ignore_pad_token_for_loss:\n",
    "#         labels[\"input_ids\"] = [\n",
    "#             [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "#         ]\n",
    "\n",
    "#     model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "#     return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c67f32d2-125e-4b7d-bee9-49a37ba1e147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if training_args.do_train:\n",
    "#     if \"train\" not in raw_datasets:\n",
    "#         raise ValueError(\"--do_train requires a train dataset\")\n",
    "#     train_dataset = raw_datasets[\"train\"]\n",
    "#     if data_args.max_train_samples is not None:\n",
    "#         max_train_samples = min(len(train_dataset), data_args.max_train_samples)\n",
    "#         train_dataset = train_dataset.select(range(max_train_samples))\n",
    "#     #with training_args.main_process_first(desc=\"train dataset map pre-processing\"):\n",
    "#     train_dataset = train_dataset.map(\n",
    "#         preprocess_function,\n",
    "#         batched=True,\n",
    "#         num_proc=data_args.preprocessing_num_workers,\n",
    "#         remove_columns=column_names,\n",
    "#         load_from_cache_file=not data_args.overwrite_cache,\n",
    "#         desc=\"Running tokenizer on train dataset\",\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "19d3a73a-c1a2-4f15-9b1e-55d3ee6970ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if training_args.do_eval:\n",
    "#     max_target_length = data_args.val_max_target_length\n",
    "#     if \"validation\" not in raw_datasets:\n",
    "#         raise ValueError(\"--do_eval requires a validation dataset\")\n",
    "#     eval_dataset = raw_datasets[\"validation\"]\n",
    "#     if data_args.max_eval_samples is not None:\n",
    "#         max_eval_samples = min(len(eval_dataset), data_args.max_eval_samples)\n",
    "#         eval_dataset = eval_dataset.select(range(max_eval_samples))\n",
    "#     #with training_args.main_process_first(desc=\"validation dataset map pre-processing\"):\n",
    "#     eval_dataset = eval_dataset.map(\n",
    "#         preprocess_function,\n",
    "#         batched=True,\n",
    "#         num_proc=data_args.preprocessing_num_workers,\n",
    "#         remove_columns=column_names,\n",
    "#         load_from_cache_file=not data_args.overwrite_cache,\n",
    "#         desc=\"Running tokenizer on validation dataset\",\n",
    "#     )\n",
    "\n",
    "# if training_args.do_predict:\n",
    "#     max_target_length = data_args.val_max_target_length\n",
    "#     if \"test\" not in raw_datasets:\n",
    "#         raise ValueError(\"--do_predict requires a test dataset\")\n",
    "#     predict_dataset = raw_datasets[\"test\"]\n",
    "#     if data_args.max_predict_samples is not None:\n",
    "#         max_predict_samples = min(len(predict_dataset), data_args.max_predict_samples)\n",
    "#         predict_dataset = predict_dataset.select(range(max_predict_samples))\n",
    "#     #with training_args.main_process_first(desc=\"prediction dataset map pre-processing\"):\n",
    "#     predict_dataset = predict_dataset.map(\n",
    "#         preprocess_function,\n",
    "#         batched=True,\n",
    "#         num_proc=data_args.preprocessing_num_workers,\n",
    "#         remove_columns=column_names,\n",
    "#         load_from_cache_file=not data_args.overwrite_cache,\n",
    "#         desc=\"Running tokenizer on prediction dataset\",\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5eb9498-250a-489d-8852-09268837b69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_pad_token_id = -100 if data_args.ignore_pad_token_for_loss else tokenizer.pad_token_id\n",
    "# data_collator = DataCollatorForSeq2Seq(\n",
    "#     tokenizer,\n",
    "#     model=model,\n",
    "#     label_pad_token_id=label_pad_token_id,\n",
    "#     pad_to_multiple_of=None,\n",
    "# )\n",
    "\n",
    "# # Metric\n",
    "# metric = load_metric(\"rouge\")\n",
    "\n",
    "# def postprocess_text(preds, labels):\n",
    "#     preds = [pred.strip() for pred in preds]\n",
    "#     labels = [label.strip() for label in labels]\n",
    "\n",
    "#     # rougeLSum expects newline after each sentence\n",
    "#     preds = [\"\\n\".join(nltk.sent_tokenize(pred)) for pred in preds]\n",
    "#     labels = [\"\\n\".join(nltk.sent_tokenize(label)) for label in labels]\n",
    "\n",
    "#     return preds, labels\n",
    "\n",
    "# def compute_metrics(eval_preds):\n",
    "#     preds, labels = eval_preds\n",
    "#     if isinstance(preds, tuple):\n",
    "#         preds = preds[0]\n",
    "#     decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "#     if data_args.ignore_pad_token_for_loss:\n",
    "#         # Replace -100 in the labels as we can't decode them.\n",
    "#         labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "#     decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "#     # Some simple post-processing\n",
    "#     decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "\n",
    "#     result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "#     # Extract a few results from ROUGE\n",
    "#     result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "\n",
    "#     prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "#     result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "#     result = {k: round(v, 4) for k, v in result.items()}\n",
    "#     return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620f1005-afd4-4a60-8632-caee8fc8e28f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd58ba12-114d-44fb-9d4e-8a2565334ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "collator = SummaryCollator(tokenizer, 'cnn_dailymail')\n",
    "dataloader = get_dataloader(raw_datasets[\"train\"], collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b7154-3094-4575-95e4-1fef241015cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9810be19-3352-45eb-9dbc-a8b25bf44fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_collator = DataCollatorForSeq2Seq(\n",
    "#         tokenizer,\n",
    "#         model=model,\n",
    "#         label_pad_token_id=label_pad_token_id,\n",
    "#         pad_to_multiple_of=None,\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810ac924-59e2-45d2-a7bf-b429de2d3c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64ad9e1d-b10b-44c8-ae26-b7135d6b4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ipu_train_dataloader = ipu_dataloader(train_dataset, tokenizer, ipu_config, training_args, data_collator, shuffle=False)\n",
    "ipu_train_dataloader = ipu_dataloader(raw_datasets[\"train\"], tokenizer, ipu_config, training_args, collator, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847bdc14-92f5-461a-8571-1c62d7235e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(ipu_train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9961e74-7ab2-439c-a6b5-d98c2a042104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    0,   243,    18,  ...,  4139,    19,     2],\n",
       "         [    0,  1640, 16256,  ...,    71,   292,     2],\n",
       "         [    0, 38959,   412,  ...,  3603,     7,     2],\n",
       "         ...,\n",
       "         [    0,  1640, 16256,  ...,  1707,     9,     2],\n",
       "         [    0,  1640, 16256,  ...,  2964,    30,     2],\n",
       "         [    0, 23122,    36,  ...,     1,     1,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([[    0, 38291,   781,  ...,  -100,  -100,  -100],\n",
       "         [    0, 16419,  1851,  ...,  -100,  -100,  -100],\n",
       "         [    0,   133,  3200,  ...,  -100,  -100,  -100],\n",
       "         ...,\n",
       "         [    0,  1620,   391,  ...,  -100,  -100,  -100],\n",
       "         [    0, 35021,  1928,  ...,  -100,  -100,  -100],\n",
       "         [    0, 15685,    34,  ...,  -100,  -100,  -100]]),\n",
       " 'decoder_input_ids': tensor([[    2,     0, 38291,  ...,     1,     1,     1],\n",
       "         [    2,     0, 16419,  ...,     1,     1,     1],\n",
       "         [    2,     0,   133,  ...,     1,     1,     1],\n",
       "         ...,\n",
       "         [    2,     0,  1620,  ...,     1,     1,     1],\n",
       "         [    2,     0, 35021,  ...,     1,     1,     1],\n",
       "         [    2,     0, 15685,  ...,     1,     1,     1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ef160-2b1c-4eeb-a213-4e2130ea3fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2312e857-ec48-440c-987e-2acc859183ae",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf70b9-28d1-4c73-affd-1b7466b49a80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07b25da7-715e-4cd6-a2d1-3f65eecae430",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import get_optimizer_scheduler, wrap_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c15372cf-6e03-4299-9547-2926f16530b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer, scheduler = get_optimizer_scheduler(model, ipu_config, training_args, ipu_train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bb202f30-f56a-4596-a4f2-0916aaf6201a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import poptorch\n",
    "from poptorch import DataLoaderMode, PoplarExecutor\n",
    "import time\n",
    "from torch import nn, optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72679314-b195-434b-af0e-2d209aeca66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if optimizer is not None and not isinstance(optimizer, poptorch.optim.Optimizer):\n",
    "    #optimizer = self._pytorch_optimizer_to_poptorch(self.optimizer, model, self.model)\n",
    "    raise Exception('Error : convert to poptorch optimzier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8936c4-089b-4cff-922a-975dcad55f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2b4834e-9cb5-451e-bdcc-130803442592",
   "metadata": {},
   "outputs": [],
   "source": [
    "opts = ipu_config.to_options()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44630c5c-4e1c-4914-a82f-b6e8c7d61bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_model = poptorch.trainingModel(\n",
    "    model.train(), options=opts, optimizer=optimizer\n",
    ")\n",
    "training_model = wrap_model(training_model, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34929867-172d-4e38-8bea-6aa5e7fcd2d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0bd92c7c-afcc-4163-9849-3fbdf7739c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/28/2022 11:02:55 - INFO - __main__ - Compiling Model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/optimum/graphcore/models/bart/modeling_bart.py:138: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/usr/local/lib/python3.6/dist-packages/optimum/graphcore/models/bart/modeling_bart.py:171: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n",
      "/usr/local/lib/python3.6/dist-packages/optimum/graphcore/models/bart/modeling_bart.py:300: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if input_shape[-1] > 1:\n",
      "Graph compilation: 100%|| 100/100 [00:22<00:00]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "04/28/2022 11:03:40 - INFO - __main__ - Compiled/Loaded model in 45.3809361460153 secs\n"
     ]
    }
   ],
   "source": [
    "if training_model.isCompiled():\n",
    "    pass\n",
    "else:\n",
    "    logger.info(\"Compiling Model...\")\n",
    "    start_compile = time.perf_counter()\n",
    "\n",
    "    sample_batch = next(iter(ipu_train_dataloader))\n",
    "    \n",
    "    if isinstance(sample_batch, tuple):\n",
    "        training_model.compile(*dict(a))\n",
    "    else:\n",
    "        training_model.compile(**dict(a))\n",
    "    duration_compilation = time.perf_counter() - start_compile\n",
    "    logger.info(f\"Compiled/Loaded model in {duration_compilation} secs\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9663e6bc-d021-4b84-93ed-b6b911809e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b7110b9b-80de-405c-9350-54e65eb5bcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0820, dtype=torch.float16)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model(**a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "0660258a-33d7-4616-b99b-776475b35c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.0820, dtype=torch.float16)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_model(**a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347637a4-675e-4314-8e92-502d0d135258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b250ab0-3817-4338-bcfa-0497b152ac6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaac14d-0064-4909-9f61-7a35aa96a664",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10badab-e1dd-4274-bed6-0b8311b62f14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1392e938-55bf-449a-8fad-9f0b63aa4dc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0dea7-c6ad-497c-aab8-27812ea93059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed65b77d-4573-49e9-9e8e-f1930229e3dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32ba12d-a8c6-4408-8481-54f4f7e7388e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da19326a-dc9d-4b78-9eeb-dd5ad638edb0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d904835-9452-4e5f-95e1-08499ad3d509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111f3958-9841-49b6-bc54-2cf92c00319b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
